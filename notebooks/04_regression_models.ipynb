{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4038ab69-d20e-4dbc-87eb-c76cf6139a58",
   "metadata": {},
   "source": [
    "# Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a736ba1-d5b2-4b19-adc4-e3bbeafdb0d5",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f4d1df-f282-4bc4-8220-0e7f4673b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and prepare the dataset\n",
    "df = pd.read_feather('../data/spotify_2000_2020.feather')\n",
    "df['is_hit'] = (df['popularity'] > 80).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb14b675-f16d-488e-918e-856f50c4bd7b",
   "metadata": {},
   "source": [
    "## Step 1: Linear Regression to Predict Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c1d122c-42c8-4e52-b821-1b834a3f52a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             popularity   R-squared:                       0.021\n",
      "Model:                            OLS   Adj. R-squared:                  0.021\n",
      "Method:                 Least Squares   F-statistic:                     884.5\n",
      "Date:                Thu, 08 May 2025   Prob (F-statistic):          2.43e-192\n",
      "Time:                        18:20:38   Log-Likelihood:            -1.5810e+05\n",
      "No. Observations:               41656   AIC:                         3.162e+05\n",
      "Df Residuals:                   41654   BIC:                         3.162e+05\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept       49.4894      0.187    264.090      0.000      49.122      49.857\n",
      "danceability     9.0454      0.304     29.740      0.000       8.449       9.642\n",
      "==============================================================================\n",
      "Omnibus:                     1575.888   Durbin-Watson:                   0.457\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4495.953\n",
      "Skew:                          -0.120   Prob(JB):                         0.00\n",
      "Kurtosis:                       4.591   Cond. No.                         7.83\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Simple linear regression using statsmodels\n",
    "model = smf.ols('popularity ~ danceability', data=df).fit()\n",
    "\n",
    "# Print summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f48ff-2977-4775-8ab1-5f3261f51841",
   "metadata": {},
   "source": [
    "### Key Results:\n",
    "\n",
    "- Intercept (β₀): 49.49 → When danceability = 0, predicted popularity ≈ 49.5\n",
    "\n",
    "- Slope (β₁): 9.05 → For every 1-unit increase in danceability, popularity increases by ~9.05 points on average\n",
    "\n",
    "- p-value for danceability: < 0.0001 → The relationship is statistically significant\n",
    "\n",
    "- R-squared = 0.021 → Danceability explains only 2.1% of the variation in popularity\n",
    "\n",
    "It’s statistically significant\n",
    "But not practically strong, because R² is just 0.021 → meaning danceability alone explains only 2.1% of popularity variation.\n",
    "\n",
    "So: it’s real, but not enough by itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcfd6fa-b014-428e-baa2-64693929b2db",
   "metadata": {},
   "source": [
    "## Step 2: Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dc8dbf0-8413-4153-b978-7d864ffd66b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>popularity</td>    <th>  R-squared:         </th>  <td>   0.049</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.049</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   427.8</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 08 May 2025</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:34:13</td>     <th>  Log-Likelihood:    </th> <td>-1.5749e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 41656</td>      <th>  AIC:               </th>  <td>3.150e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 41650</td>      <th>  BIC:               </th>  <td>3.151e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   53.4990</td> <td>    0.495</td> <td>  108.169</td> <td> 0.000</td> <td>   52.530</td> <td>   54.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>danceability</th> <td>   13.5715</td> <td>    0.368</td> <td>   36.919</td> <td> 0.000</td> <td>   12.851</td> <td>   14.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>energy</th>       <td>   -3.9210</td> <td>    0.362</td> <td>  -10.832</td> <td> 0.000</td> <td>   -4.631</td> <td>   -3.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>valence</th>      <td>   -7.4858</td> <td>    0.256</td> <td>  -29.282</td> <td> 0.000</td> <td>   -7.987</td> <td>   -6.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loudness</th>     <td>    0.1894</td> <td>    0.018</td> <td>   10.371</td> <td> 0.000</td> <td>    0.154</td> <td>    0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tempo</th>        <td>    0.0079</td> <td>    0.002</td> <td>    4.517</td> <td> 0.000</td> <td>    0.004</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1811.905</td> <th>  Durbin-Watson:     </th> <td>   0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5556.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.143</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.766</td>  <th>  Cond. No.          </th> <td>1.49e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.49e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &    popularity    & \\textbf{  R-squared:         } &      0.049   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &      0.049   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &      427.8   \\\\\n",
       "\\textbf{Date:}             & Thu, 08 May 2025 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n",
       "\\textbf{Time:}             &     18:34:13     & \\textbf{  Log-Likelihood:    } & -1.5749e+05  \\\\\n",
       "\\textbf{No. Observations:} &       41656      & \\textbf{  AIC:               } &  3.150e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &       41650      & \\textbf{  BIC:               } &  3.151e+05   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &              \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &              \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}    &      53.4990  &        0.495     &   108.169  &         0.000        &       52.530    &       54.468     \\\\\n",
       "\\textbf{danceability} &      13.5715  &        0.368     &    36.919  &         0.000        &       12.851    &       14.292     \\\\\n",
       "\\textbf{energy}       &      -3.9210  &        0.362     &   -10.832  &         0.000        &       -4.631    &       -3.212     \\\\\n",
       "\\textbf{valence}      &      -7.4858  &        0.256     &   -29.282  &         0.000        &       -7.987    &       -6.985     \\\\\n",
       "\\textbf{loudness}     &       0.1894  &        0.018     &    10.371  &         0.000        &        0.154    &        0.225     \\\\\n",
       "\\textbf{tempo}        &       0.0079  &        0.002     &     4.517  &         0.000        &        0.004    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1811.905 & \\textbf{  Durbin-Watson:     } &    0.522  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 5556.845  \\\\\n",
       "\\textbf{Skew:}          &  -0.143  & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   4.766  & \\textbf{  Cond. No.          } & 1.49e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.49e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:             popularity   R-squared:                       0.049\n",
       "Model:                            OLS   Adj. R-squared:                  0.049\n",
       "Method:                 Least Squares   F-statistic:                     427.8\n",
       "Date:                Thu, 08 May 2025   Prob (F-statistic):               0.00\n",
       "Time:                        18:34:13   Log-Likelihood:            -1.5749e+05\n",
       "No. Observations:               41656   AIC:                         3.150e+05\n",
       "Df Residuals:                   41650   BIC:                         3.151e+05\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       53.4990      0.495    108.169      0.000      52.530      54.468\n",
       "danceability    13.5715      0.368     36.919      0.000      12.851      14.292\n",
       "energy          -3.9210      0.362    -10.832      0.000      -4.631      -3.212\n",
       "valence         -7.4858      0.256    -29.282      0.000      -7.987      -6.985\n",
       "loudness         0.1894      0.018     10.371      0.000       0.154       0.225\n",
       "tempo            0.0079      0.002      4.517      0.000       0.004       0.011\n",
       "==============================================================================\n",
       "Omnibus:                     1811.905   Durbin-Watson:                   0.522\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5556.845\n",
       "Skew:                          -0.143   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.766   Cond. No.                     1.49e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.49e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple regression formula\n",
    "features = ['danceability', 'energy', 'valence', 'loudness', 'tempo']\n",
    "formula = 'popularity ~ ' + ' + '.join(features)\n",
    "\n",
    "# Fit the model\n",
    "multi_model = smf.ols(formula=formula, data=df).fit()\n",
    "\n",
    "# Show summary\n",
    "multi_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa34942-9a8f-4d59-85de-e2602e05ed19",
   "metadata": {},
   "source": [
    "## Step 3: Logistic Regression: Predicting Whether a Song is a Hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ca8ae9-3729-4e10-8f1d-cadd34c92067",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Features and target\n",
    "X = df[['danceability', 'energy', 'valence', 'loudness', 'tempo']]\n",
    "y = df['is_hit']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a712984-deb2-43c1-96ee-518877ecfe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      8242\n",
      "           1       0.00      0.00      0.00        90\n",
      "\n",
      "    accuracy                           0.99      8332\n",
      "   macro avg       0.49      0.50      0.50      8332\n",
      "weighted avg       0.98      0.99      0.98      8332\n",
      "\n",
      "Confusion Matrix:\n",
      " [[8242    0]\n",
      " [  90    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agnes/miniconda3/envs/data-science-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/agnes/miniconda3/envs/data-science-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/agnes/miniconda3/envs/data-science-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Fit the logistic regression model\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = log_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de0467-0c11-40ed-85dd-2579f4de845c",
   "metadata": {},
   "source": [
    "- The model **predicted all songs as not hits**, completely missing the rare hit class.\n",
    "- **Accuracy = 99%**, but this is misleading due to class imbalance.\n",
    "- Precision, recall, and F1-score for hit class are all **0.00**, meaning the model is not useful in its current form.\n",
    "\n",
    "Next step: Apply `class_weight='balanced'` to handle imbalance or use resampling techniques like SMOTE in model tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "735cc3b7-c9b4-4340-83f0-5f54a7a24316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report (Balanced):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.67      0.80      8242\n",
      "           1       0.02      0.67      0.04        90\n",
      "\n",
      "    accuracy                           0.67      8332\n",
      "   macro avg       0.51      0.67      0.42      8332\n",
      "weighted avg       0.98      0.67      0.79      8332\n",
      "\n",
      "Confusion Matrix:\n",
      " [[5526 2716]\n",
      " [  30   60]]\n"
     ]
    }
   ],
   "source": [
    "# Re-train with class_weight='balanced'\n",
    "log_model_balanced = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "log_model_balanced.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_balanced = log_model_balanced.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Classification Report (Balanced):\\n\", classification_report(y_test, y_pred_balanced, zero_division=0))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_balanced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90e356e-b07e-447b-942c-52d621762700",
   "metadata": {},
   "source": [
    "- Using `class_weight='balanced'`, the model now correctly identified **67% of hits** (recall = 0.67), compared to 0% before.\n",
    "- It correctly predicted **60 out of 90 hits**, a substantial improvement.\n",
    "- Precision for hits is low (0.02), meaning it predicted many false positives — but this is expected when the model is optimized for recall on rare classes.\n",
    "- Accuracy dropped to 67%, but this tradeoff is acceptable when our goal is **not to miss hits**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216180e7-7c1a-4a8b-9adc-3ee622f268f8",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "This model provides a meaningful baseline for predicting hit songs in an imbalanced setting. For better performance, next steps could include:\n",
    "- Threshold tuning\n",
    "- ROC-AUC analysis\n",
    "- More advanced models (e.g., Random Forest, XGBoost)\n",
    "- Resampling methods like SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1782bf9-147a-4f63-b1de-df1e2afd4747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
